// For more information, see https://crawlee.dev/
import { PlaywrightCrawler, log as crawleeLog } from "crawlee";
import type { Product } from "@repo/types";
export type { Product }; // æ·»åŠ è¿™è¡Œä»¥é‡æ–°å¯¼å‡º

// æ–°å¢žï¼šç»Ÿä¸€çš„çˆ¬è™«é…ç½®é€‰é¡¹æŽ¥å£
export interface ScraperOptions {
  maxRequests?: number;
  maxLoadClicks?: number;
  maxProducts?: number;
  storageDir?: string; // æ·»åŠ ï¼šå­˜å‚¨ç›®å½•å‚æ•°
  headless?: boolean; // æ·»åŠ ï¼šæŽ§åˆ¶æ˜¯å¦ä½¿ç”¨æ— å¤´æµè§ˆå™¨æ¨¡å¼ï¼Œé»˜è®¤ä¸ºtrue
  maxConcurrency?: number; // æ–°å¢žï¼šæŽ§åˆ¶æœ€å¤§å¹¶å‘æ•°
  enableDetailExtraction?: boolean; // ðŸš€ æ–°å¢žï¼šæ˜¯å¦å¯ç”¨è¯¦æƒ…é¡µæŠ“å–ï¼ˆé»˜è®¤trueï¼Œå¯è®¾ä¸ºfalseæå‡æ€§èƒ½ï¼‰
}

// æ–°å¢žï¼šç»Ÿä¸€çš„çˆ¬è™«å‡½æ•°ç±»åž‹
export type ScraperFunction = (
  startUrls: string | string[],
  options?: ScraperOptions,
  executionId?: string, // æ–°å¢ž
) => Promise<Product[] | void>; // ä¿®æ”¹è¿”å›žç±»åž‹

// Export site-specific scrapers
export * from "./sites/cettire.js";
export * from "./sites/farfetch.js";
export * from "./sites/italist.js";
export * from "./sites/mytheresa/index.js";
export * from "./sites/yoox.js";
export * from "./sites/fmtc/index.js";

// æ˜Žç¡®å¯¼å‡ºé»˜è®¤å¯¼å‡º
import mytheresaScraperDefault from "./sites/mytheresa/index.js";
import italistScraperDefault from "./sites/italist.js";
import yooxScraperDefault from "./sites/yoox.js";
import farfetchScraperDefault from "./sites/farfetch.js";
import cettireScraperDefault from "./sites/cettire.js";
import fmtcScraperDefault from "./sites/fmtc/index.js";

// é‡å‘½åå¯¼å‡ºä»¥åŒ¹é… API è·¯ç”±ä¸­çš„æœŸæœ›åç§°
export const mytheresaScraper = mytheresaScraperDefault;
export const italistScraper = italistScraperDefault;
export const yooxScraper = yooxScraperDefault;
export const farfetchScraper = farfetchScraperDefault;
export const cettireScraper = cettireScraperDefault;
export const fmtcScraper = fmtcScraperDefault;

// Import the specific scraper to test and crawlee's log
// import scrapeMytheresa from './sites/mytheresa.js'; // è¢«ä¸Šé¢çš„ mytheresaScraperDefault æ›¿ä»£
// Note: 'log' is typically imported from 'crawlee'. If you have a global 'log' or want to avoid conflicts, ensure clarity.
// For this test, we'll use crawleeLog directly or rename it as above.

crawleeLog.setLevel(crawleeLog.LEVELS.INFO); // Set log level to INFO to reduce verbose debug output

// PlaywrightCrawler crawls the web using a headless
// browser controlled by the Playwright library.
const createCrawler = () =>
  new PlaywrightCrawler({
    // Use the requestHandler to process each of the crawled pages.
    async requestHandler({
      request,
      page,
      enqueueLinks,
      log: localCrawlerLog,
      pushData,
    }) {
      const title = await page.title();
      localCrawlerLog.info(`Title of ${request.loadedUrl} is '${title}'`);

      // Save results as JSON to ./storage/datasets/default
      await pushData({ title, url: request.loadedUrl });

      // Extract links from the current page
      // and add them to the crawling queue.
      await enqueueLinks();
    },
    // Comment this option to scrape the full website.
    maxRequestsPerCrawl: 10, // å‡å°‘æµ‹è¯•æ—¶çš„è¯·æ±‚æ•°é‡
    // Uncomment this option to see the browser window.
    // launchContext: {
    //     launchOptions: {
    //         headless: false,
    //     },
    // },
  });

// Export a function to be called from admin API
export async function runMyCrawler(startUrls: string | string[]) {
  crawleeLog.info("Starting crawler...");
  const crawler = createCrawler();
  await crawler.run(Array.isArray(startUrls) ? startUrls : [startUrls]);
  crawleeLog.info("Crawler finished.");
}

// ç¤ºä¾‹ï¼šå¦‚æžœæƒ³ç›´æŽ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œæµ‹è¯• (å¯é€‰)
// async function main() {
//   console.log("Node.js process.env.NODE_ENV:", process.env.NODE_ENV);
//   crawleeLog.info("Inside main() function - STARTING");

//   if (process.env.NODE_ENV !== "test") {
//     crawleeLog.info(
//       'NODE_ENV is not "test", proceeding with scrapeMytheresa...',
//     );
//     try {
//       crawleeLog.info("Calling mytheresaScraper..."); // æ›´æ–°è°ƒç”¨
//       await mytheresaScraperDefault(); // ä½¿ç”¨é»˜è®¤å¯¼å…¥çš„ mytheresa è¿›è¡Œæµ‹è¯•
//       crawleeLog.info("mytheresaScraper finished.");
//     } catch (error) {
//       if (error instanceof Error) {
//         crawleeLog.error(
//           `Error during scrapeMytheresa call in main: ${error.message}`,
//           { stack: error.stack },
//         );
//       } else {
//         crawleeLog.error(
//           "An unknown error occurred during scrapeMytheresa call in main",
//           { errorDetail: String(error) },
//         );
//       }
//     }
//   } else {
//     crawleeLog.info('NODE_ENV is "test", skipping scrapeMytheresa in main.');
//   }
//   crawleeLog.info("Inside main() function - FINISHING");
// }

console.log("Script main.ts is being executed.");
// main()
//   .then(() => {
//     crawleeLog.info("main() promise resolved.");
//   })
//   .catch((err) => {
//     if (err instanceof Error) {
//       crawleeLog.error(
//         `Main execution error in main.ts (Promise rejection): ${err.message}`,
//         { stack: err.stack },
//       );
//     } else {
//       crawleeLog.error(
//         "An unknown error occurred in main.ts (Promise rejection)",
//         { errorDetail: String(err) },
//       );
//     }
//   });
